Questions 
I) Understand the working of the following classifier algorithms and trace the same for a sample dataset (min 10 records) which involves 2 classes (Binary Classifier) eg: 'Yes' or 'No' , 'True' or 'False'. 
   a) Decision Tree Induction
Give pseudo code and trace decision tree algorithms.
Understand attribute selection measures such as Information gain, gain ratio (use anyone for the trace).
   b) Naive Bayesian Classifier (NBC)
Read about Bayes theorem, conditional class independence, prior and posterior probabilities.
How to handle zero probability scenario (Laplacian  Estimator)
Give a short pseudo code and trace.
   c) Neural Network Classifier (Back Propagation Network(BPN))
Understand basic terminologies - topology of a network, input layer, hidden layer, output layer, activation functions, weight, bias.
Strength and limitations of a neural network.
Take a sample network to learn the basics. For instance, learning the behaviour of OR gate, AND gate.
Take a network involving atleast one hidden layer and trace the BPN algorithm assuming a target class for one epoch.
   d) SVM or Nearest Neighbour Classifier (Anyone)
Understand the algorithm/working and give the pseudocode and the trace
II) Understand the working of a simple genetic algorithm involving operators of selection, cross-over, mutation. Apply these operators to an optimisation function such as max f(x)= x3-2x2+x within a range of (0,31).
(Refer David E. Goldberg material for basics of GA)

III) Understand the working of Bucket Brigade Classifier[BBC] (discussed in Goldberg)
Concepts to focus - Credit Apportionment, Fitness and Strength of classifier.
Understand the trace given in the Goldberg textbook.
IV) Explore the scope of applying the bucket brigade classifier in the context of decision tree induction. This question doesn't require the trace. You will have to discuss how the optimization, quicker convergence supported by a BBC can be useful for decision tree induction. (Not mandatory)

V) Understand confusion matrix and various performance measures associated with classification tasks such as accuracy, sensitivity, specificity, precision, recall, F1 score etc. Consider a sample binary classifier results (TP, FP, TN, FN) and compute various measures.

VI) Clustering Algorithms (Euclidean distance may be used)
   a)Understand the working of k-means clustering algorithm. Give a pseudo code for the same and trace it for a sample dataset of your choice, clearly showing the centroid updates.

  b)Understand the working of k-medoids clustering algorithm. Give a pseudo code for the same and trace it for the sample dataset used for VI-(a), clearly showing the centroid updates. 

  c) Understand the working of hierarchical clustering algorithm- Agglomerative, Divisive and trace them for the dataset used in VI-(a). You may trace the algorithm for both the approaches and use the dendrogram to represent the clustering process pictorially as well.

VII) Survey the various distance measures used by clustering algorithms eg: Cosine, Jaccard similarity measures etc.
Explore for a minimum of 5 measures (non-Euclidean distance measures) and trace them to measure distance 2 data points.

VIII) a) Test drive/Implement Decision tree, Naive Bayes, BPN, k-means, hierarchical clustering in a platform of your choice.
        b) Test drive/Implement optimization using GA operator in a platform of your choice (Not mandatory)
        c) Test drive/Implement the bucket brigade classifier (Not mandatory)
